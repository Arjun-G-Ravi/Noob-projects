{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question Answering System\n",
    "### TOPIC: Animals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from ai import LLM\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = '' # Add your Google API key here\n",
    "dataset = load_dataset(\"MuskumPillerum/General-Knowledge\") # Add the dataset of your choice. The animals part of this dataset is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1668\n"
     ]
    }
   ],
   "source": [
    "ds = dataset['train'][32:1700] # This contains questions about animals and birds\n",
    "x = ds['Question']\n",
    "y = ds['Answer']\n",
    "print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = nltk.corpus.stopwords\n",
    "sw = stop_words.words('english')\n",
    "sw.extend(['?', '.', '\"', \"'\", '!', '#', '`'])\n",
    "sw = set(sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1317"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = {}\n",
    "\n",
    "for i,q in enumerate(x):\n",
    "    q = nltk.word_tokenize(q.lower())\n",
    "    # print(q)\n",
    "    for word in q:\n",
    "        if word not in sw:\n",
    "            if word not in vocab:\n",
    "                vocab[word] = [i]\n",
    "            else:\n",
    "                vocab[word].append(i)\n",
    "len(vocab)\n",
    "# vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not api_key:\n",
    "    with open('config.ini') as f:\n",
    "        api_key = f.read()\n",
    "\n",
    "llm = LLM(api_key)\n",
    "n = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_output(qn, retrieved_info):\n",
    "    prompt_template = f'''\n",
    "You are a Question Answering system that will accept retrieved data from a dataset. Using the retrived data, answer the query. \n",
    "Remember that all the retrived data need not be used. Use only the relevant data present in the retrieved information and complete.\n",
    "\n",
    "Query: {qn}\n",
    "\n",
    "Retrived information: \n",
    "{retrieved_info}\n",
    "\n",
    "Answer: '''\n",
    "    print(prompt_template)\n",
    "    out = llm.generate(prompt_template)\n",
    "    print(out)\n",
    "    print('cow')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are a Question Answering system that will accept retrieved data from a dataset. Using the retrived data, answer the query. \n",
      "Remember that all the retrived data need not be used. Use only the relevant data present in the retrieved information and complete.\n",
      "\n",
      "Query: hello\n",
      "\n",
      "Retrived information: \n",
      "\n",
      "\n",
      "Answer: \n",
      "I am a Question Answering system designed to answer questions based on provided data.\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "# Ideally, the similarity should be done with a better similarity index, but this works very fine in this situation\n",
    "    query = input('You: ')\n",
    "    if not query: break\n",
    "    tokens = nltk.word_tokenize(query.lower())\n",
    "    important_indices = []\n",
    "    l = -1\n",
    "    for token in tokens:\n",
    "        if token not in sw:\n",
    "            if token in vocab:\n",
    "                important_indices.extend(vocab[token])\n",
    "            l += 1\n",
    "    out = Counter(important_indices)    \n",
    "    s = ''  \n",
    "    for i,j in out.most_common(n):\n",
    "        if j>=l:\n",
    "            s += f'Q: {x[i]}  A: {y[i]}\\n'\n",
    "\n",
    "    prompt_template = f'''\n",
    "You are a Question Answering system that will accept retrieved data from a dataset. Using the retrived data, answer the query. \n",
    "Remember that all the retrived data need not be used. Use only the relevant data present in the retrieved information and complete.\n",
    "\n",
    "Query: {query}\n",
    "\n",
    "Retrived information: \n",
    "{s}\n",
    "\n",
    "Answer: '''\n",
    "    print(prompt_template)\n",
    "    print(llm.generate(prompt_template))\n",
    "    sleep(3)\n",
    "    print('-'*10)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_ENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
